#!/bin/bash

function show_help (){
    echo "usage: wikitrends [-e env_var_file] [-m master_address]"
    echo "                  [-w number_of_executor_workers]"
    echo -e "             <subcommand>\n"
    echo -e "Manage WikiTrends batch and speed layers\n"
    echo "Positional arguments:"
    echo "   <subcommand>"
    echo "   batch                                Runs batch layer job"
    echo "   speed <start|status|stop>"
    echo "             start                      Submits speed layer job"
    echo "             status <submission_id>     Gets status of given job"
    echo "             stop   <submission_id>     Kills given job"

}

WIKITRENDS_HOME="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
JAR_FILE=wikitrends-0.1.jar
JAR_PATH=${WIKITRENDS_HOME}/lib/${JAR_FILE}
HDFS_JAR_PATH=hdfs:///tmp/${JAR_FILE}
MAIN_CLASS=br.edu.ufcg.analytics.wikitrends.processing.Main

# default values
MASTER_ADDRESS=spark://hdfs-namenode:7077
TOTAL_EXECUTOR_CORES=2
ENV_VAR_FILE=${HOME}/.profile

OPTIND=1         # Reset in case getopts has been used previously in the shell.

while getopts "h?e:m:w:" opt; do
    case "$opt" in
    h|\?)
        show_help
        exit 0
        ;;
    e)  ENV_VAR_FILE=$OPTARG
        ;;
    m)  MASTER_ADDRESS=$OPTARG
        ;;
    w)  TOTAL_EXECUTOR_CORES=$OPTARG
        ;;
    esac
done

shift $((OPTIND-1))

[ "$1" = "--" ] && shift




case "$1" in
batch)
    echo "Submitting batch layer job"
	source ${ENV_VAR_FILE}
	spark-submit --master ${MASTER_ADDRESS} --total-executor-cores ${TOTAL_EXECUTOR_CORES} --class ${MAIN_CLASS} ${JAR_PATH} BATCH
    echo "Finished executing batch layer job"
    ;;
feed)
    echo "Starting data ingestor"
#	source ${ENV_VAR_FILE}
#	nohup java -cp "lib/*" 
    echo "Data ingestor is up!"
	;;
speed)
	MASTER_ADDRESS=${MASTER_ADDRESS%:*}:6066
    case $2 in
    start)
	    echo "Submitting speed layer job"
		source ${ENV_VAR_FILE}
		hdfs dfs -rm ${HDFS_JAR_PATH}
		hdfs dfs -put ${JAR_PATH} ${HDFS_JAR_PATH}
		spark-submit --supervise --deploy-mode cluster --master ${MASTER_ADDRESS} --total-executor-cores ${TOTAL_EXECUTOR_CORES} --class ${MAIN_CLASS} ${HDFS_JAR_PATH} SPEED
	    echo "Finished submitting speed layer job"
        ;;
    stop)
	    echo "Attempting to stop speed layer job"
		source ${ENV_VAR_FILE}
		spark-submit --kill $3 --master ${MASTER_ADDRESS}
	    echo "Finished speed layer job"
        ;;
    status)
	    echo "Getting status of speed layer job"
		source ${ENV_VAR_FILE}
		spark-submit --status $3 --master ${MASTER_ADDRESS}
        ;;
    esac
    ;;
web)
    case $2 in
    start)
	    echo "Starting web application"
	    nohup java -cp "lib/*" br.edu.ufcg.analytics.wikitrends.view.api.WikiTrendsAPI &
        ;;
    stop)
	    echo "Attempting to stop web application"
	    kill `ps aux | grep WikiTrendsAPI | awk '{print $2}'`
		echo "Finished speed layer job"
        ;;
    esac
    ;;
*)
    show_help
    ;;
esac
